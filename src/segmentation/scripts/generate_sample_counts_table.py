#!/usr/bin/env python3
"""Generate LaTeX table with training sample counts for segmentation experiments.

This script scans through segmentation experiments, extracts sample counts from
kfold_statistics.json and augmentation_stats.csv files, and generates:
1. A CSV file with the raw counts
2. A LaTeX table file from a template with placeholders filled in

The sample counts are divided into three categories:
- Real: Original real samples in training set
- Augmented (Traditional): Samples processed with traditional augmentation transforms
- Augmented (Synthetic): Samples generated by the diffusion model

Usage:
    python -m src.segmentation.scripts.generate_sample_counts_table \
        --experiments-dir /path/to/segmentation_experiments \
        --output-dir docs/tex/sample_counts \
        --template-path docs/tex/sample_counts/template.tex

Example:
    python -m src.segmentation.scripts.generate_sample_counts_table \
        --experiments-dir /media/mpascual/Sandisk2TB/research/epilepsy/results/segmentation/runs/segmentation_experiments \
        --output-dir docs/tex/sample_counts \
        --template-path docs/tex/sample_counts/template.tex \
        --model attentionunet
"""

from __future__ import annotations

import argparse
import json
import logging
from pathlib import Path

import pandas as pd

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# Experiment configurations
EXPERIMENTS = {
    r"$M_0$": "real_only",
    r"$M_1$": "real_traditional_augmentation",
    r"$M_2$": "real_synthetic_balance",
    r"$M_3$": "real_synthetic_traditional_augmentation",
}

# Experiments that use traditional augmentation
TRADITIONAL_AUG_EXPERIMENTS = {
    "real_traditional_augmentation",
    "real_synthetic_traditional_augmentation",
}


def load_kfold_statistics(experiment_dir: Path) -> dict:
    """Load kfold_statistics.json from experiment directory.

    Args:
        experiment_dir: Path to experiment directory (e.g., real_only_attentionunet)

    Returns:
        Dictionary with aggregated statistics across all folds
    """
    stats_path = experiment_dir / "kfold_information" / "kfold_statistics.json"

    if not stats_path.exists():
        logger.warning(f"kfold_statistics.json not found at {stats_path}")
        return {"real": 0, "synthetic": 0, "total": 0}

    with open(stats_path) as f:
        data = json.load(f)

    # Aggregate statistics across all folds (use mean)
    real_counts = []
    synthetic_counts = []
    total_counts = []

    for fold_data in data:
        train = fold_data.get("train", {})
        real_counts.append(train.get("real", 0))
        synthetic_counts.append(train.get("synthetic", 0))
        total_counts.append(train.get("total", 0))

    return {
        "real": sum(real_counts) / len(real_counts) if real_counts else 0,
        "synthetic": sum(synthetic_counts) / len(synthetic_counts) if synthetic_counts else 0,
        "total": sum(total_counts) / len(total_counts) if total_counts else 0,
        "real_per_fold": real_counts,
        "synthetic_per_fold": synthetic_counts,
    }


def load_augmentation_stats(experiment_dir: Path, n_folds: int = 5) -> dict:
    """Load augmentation statistics from CSV files.

    For experiments with traditional augmentation, this loads the augmentation
    stats CSV from each fold and computes summary statistics.

    Args:
        experiment_dir: Path to experiment directory
        n_folds: Number of folds

    Returns:
        Dictionary with augmentation statistics
    """
    total_augmented_samples = 0
    total_augmentations_applied = 0
    augmentation_transforms = [
        "RandAdjustContrastdNeg1To1_count",
        "RandFlip_count",
        "RandGaussianNoise_count",
        "RandGaussianSmooth_count",
        "RandRotate_count",
        "RandZoom_count",
    ]

    found_any = False

    for fold_idx in range(n_folds):
        csv_path = (
            experiment_dir
            / f"fold_{fold_idx}"
            / "csv_logs"
            / f"fold_{fold_idx}_augmentation_stats.csv"
        )

        if not csv_path.exists():
            continue

        found_any = True
        df = pd.read_csv(csv_path)

        # Sum total_samples across all epochs for this fold
        # This represents total samples processed through augmentation
        total_augmented_samples += df["total_samples"].sum()

        # Sum all augmentation transform counts
        for transform in augmentation_transforms:
            if transform in df.columns:
                total_augmentations_applied += df[transform].sum()

    if not found_any:
        return {"augmented_samples": 0, "augmentations_applied": 0, "has_augmentation": False}

    return {
        "augmented_samples": total_augmented_samples,
        "augmentations_applied": total_augmentations_applied,
        "has_augmentation": True,
        "samples_per_epoch_mean": total_augmented_samples / (n_folds * len(df))
        if found_any
        else 0,
    }


def get_experiment_stats(
    experiments_dir: Path,
    experiment_name: str,
    model: str,
) -> dict:
    """Get statistics for a single experiment.

    Args:
        experiments_dir: Base directory containing all experiments
        experiment_name: Name of experiment (e.g., 'real_only')
        model: Model name (e.g., 'attentionunet')

    Returns:
        Dictionary with real, traditional_aug, and synthetic counts
    """
    experiment_dir = experiments_dir / f"{experiment_name}_{model}"

    if not experiment_dir.exists():
        logger.warning(f"Experiment directory not found: {experiment_dir}")
        return {"real": 0, "traditional_aug": 0, "synthetic": 0}

    # Load kfold statistics
    kfold_stats = load_kfold_statistics(experiment_dir)

    # Load augmentation statistics if applicable
    aug_stats = {"has_augmentation": False, "augmented_samples": 0}
    if experiment_name in TRADITIONAL_AUG_EXPERIMENTS:
        aug_stats = load_augmentation_stats(experiment_dir)

    # Compute counts
    real_count = int(round(kfold_stats["real"]))
    synthetic_count = int(round(kfold_stats["synthetic"]))

    # Traditional augmentation count:
    # If traditional augmentation is used, the count represents the training samples
    # that went through augmentation (all of them)
    if aug_stats["has_augmentation"]:
        # Use total training samples as the augmented count
        traditional_count = int(round(kfold_stats["total"]))
    else:
        traditional_count = 0

    return {
        "real": real_count,
        "traditional_aug": traditional_count,
        "synthetic": synthetic_count,
        "total": int(round(kfold_stats["total"])),
        "has_traditional_aug": aug_stats["has_augmentation"],
    }


def generate_csv(
    experiments_dir: Path,
    model: str,
    output_path: Path,
) -> pd.DataFrame:
    """Generate CSV with sample counts for all experiments.

    Args:
        experiments_dir: Base directory containing all experiments
        model: Model name
        output_path: Path to save CSV

    Returns:
        DataFrame with sample counts
    """
    rows = []

    for label, experiment_name in EXPERIMENTS.items():
        stats = get_experiment_stats(experiments_dir, experiment_name, model)

        rows.append(
            {
                "label": label,
                "experiment": experiment_name,
                "real": stats["real"],
                "traditional_aug": stats["traditional_aug"],
                "synthetic": stats["synthetic"],
                "total": stats["total"],
            }
        )

        logger.info(
            f"{label} ({experiment_name}): "
            f"Real={stats['real']}, Traditional={stats['traditional_aug']}, "
            f"Synthetic={stats['synthetic']}"
        )

    df = pd.DataFrame(rows)
    df.to_csv(output_path, index=False)
    logger.info(f"Saved CSV to {output_path}")

    return df


def generate_latex(
    df: pd.DataFrame,
    template_path: Path,
    output_path: Path,
) -> None:
    """Generate LaTeX table from template and data.

    Args:
        df: DataFrame with sample counts
        template_path: Path to LaTeX template
        output_path: Path to save generated LaTeX
    """
    # Read template
    with open(template_path) as f:
        template = f.read()

    # Create replacement dictionary
    replacements = {}
    for idx, (label, experiment_name) in enumerate(EXPERIMENTS.items()):
        row = df[df["experiment"] == experiment_name].iloc[0]

        prefix = f"M{idx}"
        replacements[f"{{{{{prefix}_LABEL}}}}"] = label
        replacements[f"{{{{{prefix}_REAL}}}}"] = str(int(row["real"]))

        # For traditional augmentation, show dash if not used
        trad_val = int(row["traditional_aug"])
        replacements[f"{{{{{prefix}_TRAD}}}}"] = str(trad_val) if trad_val > 0 else "---"

        # For synthetic, show dash if not used
        synth_val = int(row["synthetic"])
        replacements[f"{{{{{prefix}_SYNTH}}}}"] = str(synth_val) if synth_val > 0 else "---"

    # Apply replacements
    output = template
    for placeholder, value in replacements.items():
        output = output.replace(placeholder, value)

    # Write output
    with open(output_path, "w") as f:
        f.write(output)

    logger.info(f"Saved LaTeX to {output_path}")


def main():
    """CLI entrypoint."""
    parser = argparse.ArgumentParser(
        description="Generate LaTeX table with training sample counts.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python -m src.segmentation.scripts.generate_sample_counts_table \\
        --experiments-dir /path/to/segmentation_experiments \\
        --output-dir docs/tex/sample_counts \\
        --template-path docs/tex/sample_counts/template.tex
        """,
    )

    parser.add_argument(
        "--experiments-dir",
        type=str,
        required=True,
        help="Directory containing segmentation experiments",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        required=True,
        help="Output directory for CSV and LaTeX files",
    )
    parser.add_argument(
        "--template-path",
        type=str,
        required=True,
        help="Path to LaTeX template file",
    )
    parser.add_argument(
        "--model",
        type=str,
        default="attentionunet",
        choices=["attentionunet", "segresnet", "unetr"],
        help="Model name to use for experiment directories (default: attentionunet)",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging",
    )

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Convert paths
    experiments_dir = Path(args.experiments_dir)
    output_dir = Path(args.output_dir)
    template_path = Path(args.template_path)

    # Validate paths
    if not experiments_dir.exists():
        raise FileNotFoundError(f"Experiments directory not found: {experiments_dir}")
    if not template_path.exists():
        raise FileNotFoundError(f"Template file not found: {template_path}")

    # Create output directory
    output_dir.mkdir(parents=True, exist_ok=True)

    # Generate CSV
    csv_path = output_dir / "sample_counts.csv"
    df = generate_csv(experiments_dir, args.model, csv_path)

    # Generate LaTeX
    latex_path = output_dir / "sample_counts.tex"
    generate_latex(df, template_path, latex_path)

    logger.info("Done!")


if __name__ == "__main__":
    main()
