# configs/models/unetr.yaml
model:
  name: "UNETR"
  spatial_dims: 2
  in_channels: 1
  out_channels: 1
  img_size: [128, 128]         # Must match your input slice size
  feature_size: 16             # Dimension of the embedding
  hidden_size: 768             # Transformer hidden dimension
  mlp_dim: 3072                # Dimension of the MLP in the transformer
  num_heads: 12                # Number of attention heads
  pos_embed: "perceptron"      # Positional embedding type
  norm_name: "instance"
  res_block: true              # Use residual blocks in the decoder
  dropout_rate: 0.0

# Transformer architectures often need lower learning rates
training:
  optimizer:
    lr: 1.0e-4