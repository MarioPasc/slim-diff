# Classification Module: Real vs. Synthetic Quality Assessment

This module evaluates whether synthetic MRI FLAIR images and lesion masks
generated by the JS-DDPM are distinguishable from real data. A simple CNN
classifier is trained on lesion-centered patches; higher AUC indicates
lower synthesis quality.

## Prerequisites

- Trained diffusion model replicas at the configured `results_base_dir`
- Real slice cache at the configured `cache_dir`
- Python environment with project dependencies (`pip install -e .`)
- For wavelet analysis: `pip install PyWavelets>=1.4.0`

## Pipeline Execution Order

The pipeline has four stages:

```
[1] Patch Extraction  -->  [2] Classification  -->  [3] Diagnostics  -->  [4] Report
                      \                              ^
                       \-----------------------------/
                         (all except GradCAM can skip Stage 2)
```

---

### Stage 1: Patch Extraction

Extracts lesion-centered patches from both real slices and synthetic replicas.

**Note on precision**: Previously, replicas were stored as `float16` (~20K unique
values vs ~4.3M for real float32 data). This quantization signature alone yielded
AUC=1.0. The default has been changed to `float32` for new generations (see
`--dtype` flag in `jsddpm-replicas`). For existing float16 replicas, the
diagnostics module (Stage 3) applies dithering to remove this artifact before analysis.

```bash
# Extract patches for all experiments
python -m src.classification extract \
    --config src/classification/config/classification_task.yaml \
    --all

# Extract for a single experiment
python -m src.classification extract \
    --config src/classification/config/classification_task.yaml \
    --experiment velocity_lp_1.5

# Extract real patches only (for control experiment)
python -m src.classification extract \
    --config src/classification/config/classification_task.yaml
```

**Output**: `{output.base_dir}/patches/{experiment}/real_patches.npz` and `synthetic_patches.npz`

Each NPZ contains:
- `patches`: (N, 2, 96, 96) float32 — channel 0 = FLAIR image, channel 1 = lesion mask
- `z_bins`: (N,) int32 — axial position bin
- `subject_ids`, `sources`, `replica_ids`, `sample_indices`

---

### Stage 2: Classification

Trains a simple CNN (3 conv blocks, GAP, 2 FC layers) to distinguish real (label=0)
from synthetic (label=1) patches via 5-fold cross-validation.

```bash
# Run all experiments across all input modes (joint, image_only, mask_only)
python -m src.classification run-all \
    --config src/classification/config/classification_task.yaml \
    --include-control

# Run a single experiment with a specific input mode
python -m src.classification run \
    --config src/classification/config/classification_task.yaml \
    --experiment velocity_lp_1.5 \
    --input-mode joint
```

**Output**:
- `{output.base_dir}/results/{experiment}/{mode}/experiment_result.json` — AUC, CI, per-zbin metrics
- `{output.base_dir}/checkpoints/{experiment}/{mode}/fold{i}_best.ckpt` — trained model weights

---

### Stage 3: Diagnostics

After observing AUC=1.0, this stage identifies **what** makes synthetic images
distinguishable. It first removes the float16 quantization artifact via precision-aware
dithering, then runs comprehensive analyses to detect genuine model-level differences.

**Dependencies**: Most analyses only require the extracted patches (Stage 1) or raw
replica files. Only **GradCAM** requires the trained classifier checkpoints from Stage 2.
You can run all other analyses without running the classification first:

| Analysis | Requires Stage 1 (patches) | Requires Stage 2 (checkpoints) |
|----------|:--------------------------:|:-------------------------------:|
| Dithering | Yes | No (trains its own classifiers) |
| GradCAM | Yes | **Yes** |
| Spectral, Texture, Bands | Yes | No |
| Pixel Stats, Distributions, Boundary, Wavelet | Yes | No |
| Background, Spatial Correlation, Global Frequency | No (uses raw replicas) | No |

```bash
# Run the full diagnostic suite for one experiment
python -m src.classification diagnose \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5 \
    --component all \
    --gpu 0

# Or equivalently via the standalone entry point
python -m src.classification.diagnostics run-all \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5 \
    --gpu 0
```

#### Individual analyses (can be run separately):

```bash
# 1. Dithering + re-classification (removes float16 artifact, measures residual AUC)
python -m src.classification.diagnostics dither \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5

# 2. GradCAM spatial attention maps (requires trained checkpoints from Stage 2)
python -m src.classification.diagnostics gradcam \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5 \
    --gpu 0

# 3. Spectral analysis (PSD, spectral slope, frequency-band power)
python -m src.classification.diagnostics spectral \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5

# 4. Texture analysis (GLCM, LBP, gradient magnitudes)
python -m src.classification.diagnostics texture \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5

# 5. Frequency band decomposition
python -m src.classification.diagnostics bands \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5

# 6. Per-pixel statistical tests (Welch's t-test, FDR correction)
python -m src.classification.diagnostics pixel-stats \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5

# 7. Distribution tests (KS, Wasserstein, per-tissue)
python -m src.classification.diagnostics distributions \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5

# 8. Lesion boundary analysis (gradient profiles, sharpness, transition width)
python -m src.classification.diagnostics boundary \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5

# 9. Wavelet decomposition (multi-scale energy comparison)
python -m src.classification.diagnostics wavelet \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5

# 10. Background consistency (full 160x160 images)
python -m src.classification.diagnostics background \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5

# 11. Spatial autocorrelation (full images, correlation length)
python -m src.classification.diagnostics spatial-correlation \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5

# 12. Global frequency analysis (full images)
python -m src.classification.diagnostics global-frequency \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5
```

**Output**: `{diagnostics.output.base_dir}/{experiment}/` with per-analysis subdirectories
containing JSON results and PNG/PDF plots.

---

### Stage 4: Report Generation

Aggregates all diagnostic findings into a ranked summary.

```bash
python -m src.classification.diagnostics report \
    --config src/classification/diagnostics/config/diagnostics.yaml \
    --experiment velocity_lp_1.5
```

**Output**: `{diagnostics.output.base_dir}/{experiment}/report/`
- `diagnostics_report.json` — structured findings, ranked by significance
- `findings_summary.png/pdf` — visual summary table

---

## Running All Experiments

To process all 9 experiments sequentially:

```bash
CONFIG="src/classification/diagnostics/config/diagnostics.yaml"

for exp in epsilon_lp_1.5 epsilon_lp_2.0 epsilon_lp_2.5 \
           velocity_lp_1.5 velocity_lp_2.0 velocity_lp_2.5 \
           x0_lp_1.5 x0_lp_2.0 x0_lp_2.5; do
    echo "=== Processing: $exp ==="
    python -m src.classification.diagnostics run-all \
        --config "$CONFIG" \
        --experiment "$exp" \
        --gpu 0
done
```

---

## Interpreting Results

### Dithering Stage (Most Important First Step)

| Residual AUC | Interpretation |
|--------------|----------------|
| ~0.5 | Float16 was the only issue. Fix storage format. |
| 0.5 - 0.7 | Minor model artifacts. May be acceptable for downstream tasks. |
| 0.7 - 0.9 | Significant model artifacts. See spectral/texture analyses for specifics. |
| > 0.9 | Severe model artifacts beyond quantization. |

### Spectral Analysis

- **Steeper synthetic slope**: Model over-smooths (lacks high-frequency detail)
- **Shallower synthetic slope**: Excess high-frequency noise or ringing
- **Per-band divergence**: Identifies which frequency range is most affected

### Texture Analysis

- **High GLCM effect sizes**: Microstructure differences (contrast, homogeneity)
- **LBP histogram divergence**: Local pattern differences
- **Gradient magnitude shift**: Edge sharpness differences

### Boundary Analysis

- **Higher synthetic sharpness**: Over-crisp lesion boundaries (unrealistic)
- **Lower synthetic sharpness**: Blurred boundaries (loss of detail)
- **Wider transition**: Gradual lesion-to-tissue transition (smoothing artifact)

---

## Configuration Files

| File | Purpose |
|------|---------|
| `src/classification/config/classification_task.yaml` | Classification experiments, data paths, training settings |
| `src/classification/diagnostics/config/diagnostics.yaml` | Diagnostic analyses, thresholds, output paths |

---

## Module Structure

```
src/classification/
├── __init__.py
├── __main__.py                  # CLI: extract, run, run-all, report, diagnose
├── config/
│   └── classification_task.yaml
├── data/
│   ├── dataset.py               # ClassificationDataset
│   └── patch_extractor.py       # PatchExtractor (real + synthetic)
├── models/
│   ├── factory.py               # build_model()
│   └── simple_cnn.py            # SimpleCNNClassifier, ResNetClassifier
├── training/
│   └── lit_module.py            # ClassificationLightningModule
├── evaluation/
│   └── metrics.py               # AUC, bootstrap CI, permutation tests
├── scripts/
│   ├── extract_patches.py
│   ├── run_experiment.py
│   └── run_all_experiments.py
└── diagnostics/                 # Diagnostic analysis suite
    ├── config/
    │   └── diagnostics.yaml
    ├── preprocessing/
    │   └── dithering.py         # Float16 dithering + re-classification
    ├── xai/
    │   ├── gradcam.py           # GradCAM spatial heatmaps
    │   └── aggregation.py       # Per-class/zbin aggregation
    ├── feature_probes/
    │   ├── spectral.py          # Power spectral density
    │   ├── texture.py           # GLCM, LBP, gradients
    │   └── frequency_bands.py   # Band-pass analysis
    ├── statistical/
    │   ├── pixel_stats.py       # Per-pixel t-tests (FDR corrected)
    │   ├── distribution_tests.py # KS, Wasserstein
    │   ├── boundary_analysis.py # Lesion edge profiles
    │   └── wavelet_analysis.py  # Multi-scale DWT
    ├── full_image/
    │   ├── background_analysis.py    # Background noise detection
    │   ├── spatial_correlation.py    # Autocorrelation structure
    │   └── global_frequency.py       # Full-image PSD
    ├── reporting/
    │   └── summary_report.py    # Aggregated findings
    ├── cli.py                   # Diagnostics CLI
    └── utils.py                 # Shared data loading utilities
```
