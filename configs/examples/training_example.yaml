# SLIM-Diff Training Configuration Example
# =========================================
#
# This configuration trains the joint diffusion model for paired FLAIR/mask
# synthesis. Uses x0-prediction with Lp norm + Focal Frequency Loss.
#
# Usage:
#   slimdiff-train --config configs/examples/training_example.yaml
#
# Key hyperparameters to tune:
#   - training.max_epochs: Training duration
#   - training.optimizer.lr: Learning rate
#   - loss.lp_norm.p: Lp norm exponent (2.0 = MSE, <2 = robust, >2 = edge emphasis)
#   - training.self_conditioning.probability: Self-conditioning probability

# =============================================================================
# Experiment Metadata
# =============================================================================
experiment:
  name: "slimdiff_training_example"
  output_dir: "./outputs/slimdiff_training"
  seed: 42

# =============================================================================
# Data Configuration
# =============================================================================
data:
  # Path to pre-built slice cache (created with slimdiff-cache)
  # IMPORTANT: Update this path to your actual cache location
  cache_dir: "/path/to/your/slice_cache"

  batch_size: 32
  num_workers: 0  # Set to 0 to avoid CUDA multiprocessing issues
  pin_memory: true

  # Transform settings (must match cache configuration)
  transforms:
    target_spacing: [1.25, 1.25, 1.25]
    roi_size: [160, 160, 160]
    intensity_norm:
      type: "percentile"
      lower: 0.5
      upper: 99.5
      b_min: -1.0
      b_max: 1.0
      clip: true

  slice_sampling:
    z_range: [34, 115]
    filter_empty_brain: true
    brain_threshold: -0.9
    brain_min_fraction: 0.05

  lesion_oversampling:
    enabled: true
    mode: "balance"
    weight: 3.0

# =============================================================================
# Conditioning Configuration
# =============================================================================
conditioning:
  z_bins: 30
  use_sinusoidal: true
  max_z: 159

  cfg:
    enabled: false
    null_token: 60
    dropout_prob: 0.1

# =============================================================================
# Model Configuration
# =============================================================================
model:
  type: "DiffusionModelUNet"
  spatial_dims: 2
  in_channels: 2   # [image, mask]
  out_channels: 2  # [image, mask]

  # Anatomical conditioning (recommended)
  anatomical_conditioning: true
  anatomical_conditioning_method: "cross_attention"
  cross_attention_dim: 256

  # Optional: Path to anatomical encoder config
  # anatomical_encoder_config: "src/diffusion/config/anatomical_encoder.yaml"

  # UNet architecture
  channels: [64, 128, 256, 256]
  attention_levels: [false, false, true, true]
  num_res_blocks: 2
  num_head_channels: 32

  norm_name: "GROUP"
  norm_num_groups: 32
  dropout: 0.0
  resblock_updown: false
  use_class_embedding: true
  with_conditioning: false  # Auto-enabled for cross_attention method

# =============================================================================
# Diffusion Scheduler Configuration
# =============================================================================
scheduler:
  type: "DDPM"
  num_train_timesteps: 1000
  schedule: "cosine"
  beta_start: 0.0015
  beta_end: 0.0195
  sig_range: 6.0

  # x0-prediction is crucial for good mask quality
  prediction_type: "v_prediction"

  clip_sample: true
  clip_sample_range: 1.0

# =============================================================================
# Sampler Configuration (for validation/visualization)
# =============================================================================
sampler:
  type: "DDIM"
  num_inference_steps: 400
  eta: 0.2  # 0.0 = deterministic DDIM, 1.0 = DDPM
  guidance_scale: 1.0

# =============================================================================
# Training Configuration
# =============================================================================
training:
  batch_size: 32
  num_workers: 0
  pin_memory: true

  # Self-conditioning (recommended)
  self_conditioning:
    enabled: true
    probability: 0.5

  # Optimizer
  optimizer:
    type: "AdamW"
    lr: 1.0e-4
    weight_decay: 1.0e-4
    betas: [0.9, 0.999]
    eps: 1.0e-8

  # Learning rate scheduler
  lr_scheduler:
    type: "CosineAnnealingLR"
    T_max: null  # Set to max_epochs if null
    eta_min: 1.0e-6

  # Training duration
  max_epochs: 1000
  max_steps: null

  # Mixed precision and gradient handling
  precision: "16-mixed"
  gradient_clip_val: 1.0
  gradient_clip_algorithm: "norm"
  accumulate_grad_batches: 1

  # Validation
  val_check_interval: 1.0
  check_val_every_n_epoch: 1

  # Early stopping
  early_stopping:
    enabled: true
    monitor: "val/loss"
    patience: 50
    mode: "min"

  # Exponential Moving Average
  ema:
    enabled: true
    decay: 0.999
    update_every: 1
    update_start_step: 0
    store_on_cpu: true
    use_buffers: true
    use_for_validation: true
    export_to_checkpoint: true

# =============================================================================
# Loss Configuration
# =============================================================================
loss:
  # Lp norm + Focal Frequency Loss with group uncertainty weighting
  mode: "mse_lp_norm_ffl_groups"

  # Lp norm: p > 2 emphasizes large errors (good for lesion boundaries)
  lp_norm:
    p: 2.25

  # Group uncertainty weighting (Kendall et al.)
  group_uncertainty_weighting:
    enabled: true
    initial_log_vars: [0.0, 0.5]  # [lp_norm_group, ffl_group]
    learnable: true
    clamp_range: [-5.0, 5.0]
    intra_group_weights: [1.0, 1.0, 1.0]

  # Focal Frequency Loss for edge sharpness
  ffl:
    enabled: true
    loss_weight: 1.0
    alpha: 1.2
    patch_factor: 2
    ave_spectrum: false
    log_matrix: true
    batch_matrix: false

  # Lesion pixel overweighting
  lesion_weighted_image:
    enabled: true
    lesion_weight: 2.0
    background_weight: 1.0

  lesion_weighted_mask:
    enabled: true
    lesion_weight: 2.0
    background_weight: 1.0

  # Standard uncertainty weighting (disabled in favor of group weighting)
  uncertainty_weighting:
    enabled: false
    initial_log_vars: [0.0, 0.0]
    learnable: true
    clamp_range: [-5.0, 5.0]

# =============================================================================
# Postprocessing Configuration
# =============================================================================
postprocessing:
  zbin_priors:
    enabled: true
    priors_filename: "zbin_priors_brain_roi.npz"
    prob_threshold: 0.20
    dilate_radius_px: 1
    gaussian_sigma_px: 0.7
    min_component_px: 500
    n_first_bins: 5
    max_components_for_first_bins: 3
    relaxed_threshold_factor: 0.1
    fallback: "prior"
    apply_to: ["validation", "visualization", "generation"]
    background_value: -1.0
    use_prior_directly: true

# =============================================================================
# Logging Configuration
# =============================================================================
logging:
  log_every_n_steps: 50

  logger:
    type: "wandb"
    wandb:
      project: "slimdiff"
      entity: null  # Set to your wandb entity or leave null for default
      name: slimdiff_example
      tags: ["slimdiff", "diffusion", "medical-imaging"]
      notes: "SLIM-Diff training example"
      offline: false  # Set to true for offline logging

  checkpointing:
    save_top_k: 1
    monitor: "val/loss"
    mode: "min"
    save_last: false
    every_n_epochs: 1
    filename: "slimdiff-{epoch:04d}-{val_loss:.4f}"

  callbacks:
    gradient_norm:
      enabled: true
      log_every_n_steps: 100

    snr:
      enabled: true
      log_every_n_epochs: 5
      n_samples: 100

    prediction_quality:
      enabled: true
      log_every_n_epochs: 5
      n_samples: 100
      timestep_bins: 10

    anatomical_encoder:
      enabled: true

# =============================================================================
# Visualization Configuration
# =============================================================================
visualization:
  enabled: true
  every_n_epochs: 1
  z_bins_to_show: null  # Auto-select
  n_samples_per_condition: 1

  overlay:
    enabled: true
    alpha: 0.5
    color: [255, 0, 0]
    threshold: 0.3

  save_png: true
  save_npz: false

# =============================================================================
# Generation Configuration
# =============================================================================
generation:
  n_per_condition: 100
  z_bins: null  # All bins
  classes: [0, 1]
  output_format: "npz"
  save_individual: true
  create_index_csv: true
